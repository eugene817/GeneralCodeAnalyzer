# Services

Здесь находится несколько важных файлов:

### Ядро
- `services.go`
### Экзекуторы (исполнители)
- `llm_executor.go`
- `python_executor.go`
- `c_executor.go`
- `sql_executor.go`
### Генерация рекомендаций
- `recommendations.go`
### Инструменты
- `utils.go`


## Ядро
- `services.go`
В ядре не происходит многого, описывается импорт, интерфейс сервиса и 
функиця для создания его инстанции

Структура `Service` содержит в себе переменную `apiSvc` типа `*api.API`,
Это указатель на API моей библиотеки `Cowdocs`, чтобы каждая функция сервиса была
подключена к одной инстанции API, изначально было сделанно так что в каждой функции
создавалась новая инстация API, но в последствии я решил от этого отказаться в угоду
упрощения, облегчения и объединения сервисов

Функция `NewService` получает в параметрах вышеупомянутый API и возвращает структуру
сервисов

## Экзекуторы

### `c_executor.go`

В начале файла описываются две функции создания конфига контейнеров:

1. `makeConfigC` принимает код в языке C и возвращает структуру `ContainerConfig`
внутри происходит запись скрипта `bash` который записывает код C в файл, компилирует
его и запускает. Все это происходит в контейнере `gcc:4.9`, который по умолчанию содержит
в себе `gcc`

2. `makeConfigCLint` практически идентичная функция с предыдущей, но две существенные разницы.
Первая это скрип, вместо того чтобы запустить файл, запускается анализ файла через clang, а второе
это контейнер `silkeh/clang`, который имеет предустановленный `clang`

Дальше идут три похожие функции: `LintCInContainer`, `ExecuteCInContainer`, `ExecuteCWithMetrics`
Которые соответственно запускают контейнер со статическим анализом, контейнер с запуском кода но без метрик
и контейнер с запуском кода и метриками, 
в `ExecuteCWithMetrics` используется вспомогательная функция измерения времени, которая запускается с помощью
ключевого слова `defer` которая гарантирует что по окончанию действия функции `ExecuteCWithMetrics` запустится
функция `timeTrack`


### `python_executor.go`
По аналогии с `c_executor.go` здесь находится 5 функций, первые две из которых это создание
двух разных конфигураций контейнера

`makeConfigPython` на вход получает код python, создает скрипт который запишет этот код в файл и запустит его
в контейнере `python:3`

`makeConfigPythonLint` получит на входе код питона, в скрипте запишет его в файл и запустит статический
анализ ошибок через `flake8`, так же думаю что можно попробовать использовать инструмент `ruff` вместо `flake8` 
(более современная альтернатива). И поскольку в открытых репозиториях не было контейнера чисто с `flake8`, было принято
решение создать его и выложить в открытый доступ
```Dockerfile
FROM python:3.10-slim

RUN pip install --no-cache-dir flake8

ENTRYPOINT []

WORKDIR /work
```
Этот контейнер основывается на контейнере с установленным python:3.10
и все что он делает это устанавливает `flake8` через пакетный менеджер `pip`

Дальше для того чтобы собрать этот образ, в директории где лежит `Dockerfile`,
запустил команду 
```bash
docker build -t python-flake8:latest .
```

А потом, поскольку у меня есть аккаунт на Dockerhub и я уже залогинился через `docker cli`
мне осталось написать
```bash
docker push luferchikz/python-flake8:latest
```

И все, контейнер доступен в открытом доступе и можно его получить на любом устройстве где установлен docker,
надо лишь написать
```bash
dokcer pull luferchikz/python-flake8:latest
```


Дальше идут три функции `LintPythonInContainer`, `ExecutePythonInContainer` и `ExecutePythonWithMetrics`,
которые соответственно запускают контейнер со статическим анализом, запускают контейнер с запуском кода без метрик,
и запускают контейнер с запуском кода и метриками


### `llm_executor.go`
Поскольку это лишь примерная версия приложения, то увеличивать его общий вес засчет контейнера с LLM (+5gb), то
решил сохранить функционал, но сделать его в форме запросов на локальный LLM сервер `ollama`, логика работы с ИИ
осталась бы такая же, только в `docker-compose.yml` нужно добавить еще один сервис

В начале файла находятся две структуры. Первая это `GenerateRequest`, которая содержит в себе поля:
`Model` - модель к которой будет происходит запрос, `Stream` - переменная типа bool, которая указывает на то в какой
версии возвращать ответ, либо в форме потока пока модель генерирует, либо подождать ответа модели и сразу вернуть все
и `Prompt` - текстовый запрос в нейросеть

Вторая структура это `GenerateResponse`, которая содержит поля `Model`, `Response` - ответ от модели, `DoneReason` -
статус ответа модели, `TotalDuration` - общая продолжительность от полученного запроса до возврата ответа

И дальше идет функция `QuerryOllama`, которая на входе получает строки `prompt`, `model` и возвращает ответ
Внутри происходит создание `url` для запроса, создание структуры запроса (`GenerateRequest`), его парсинг в
json, отправка запроса типа `POST` на адрес ендпоинта нейросети для генерации ответа, с запросом в `body`

Дальше читается `body` ответа, парсится на структуру `GenerateResponse` и проверяется статус ответа.
В конце возвращается ответ от нейросети, тоесть `GenerateResponse.Response`


### `sql_executor.go`

В начале функция `makeConfigSQL` которая принимает два параметра: `sqlQuerry`, `initSQL` и возвращает конфигурацию контейнера
`keinos/sqlite3` с установленым `sqlite3`, контейнер записывает базу данных `initSQL` и запускает `sqlQuerry` на этой базе данных

Дальше 3 функции `ExecuteSQLInContainer`, `ExecuteSQLWithMetrics` и `AnalyzeQuerryInContainer`,
Первые две функции запускают контейнер с и без метрик соответственно, а вот `AnalyzeQuerryInContainer`
добавляет к sql querry "EXPLAIN QUERY PLAN ", что в свою очередь является командой `sql` для того чтобы
расписать как будет выполняться запрос sql

## Генерация рекомендаций


### `recommendations.go`
Этот модуль имеет чисто демонстративную цель, поскольку он имеет две функции, для генерации рекомендаций,
которые должны на основе общепринятых практик, статистик анализа кода писать общие рекомендации для улучшения
кода, но поскольку к приложению подключена модель искусственного интеллекта, то рекомендации оставлены ей


## Инструменты

### `utils.go`
Здесь находится функция `timeTrack`, которая принимает время старта и название и возвращает
кол-во времени прошедшего с время старта и добавляет название, чтобы понимать где мы измеряли время
Вместо того чтобы где-то отдельно записывать время старта и потом вызывать эту функцию, в коде используется
метод `defer` и `time.Now()`, который работает так что в начале функции время которой мы хотим измерить 
пишется 
```go
defer timeTrack(time.Now(), "Функция которую хотим измерить")
```
Где поскольку мы передаем в параметрах функию получения нынешнего времени, она сразу записывается
как время начала функции, и не изменяется. Потом благодаря `defer` функция вызывается в конце, а если быть
точнее сразу после завершения функции которой мы хотим измерить, мы измеряем точное время работы функции
